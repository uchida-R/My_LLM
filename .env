
EMBED_MODEL="intfloat/multilingual-e5-large"

# Ollamaにインストールされているモデルから選ぶ
LLM_MODEL="gemma3:12b"
#ollamaのコンテナがollamaという名前で同一dockernetwork上で起動していることを前提としています。
OLLAMA_HOST="http://ollama:11434"
#chromaのコンテナがchromadbという名前で同一dockernetwork上で起動していることを前提としています。
VECDB_HOSTNAME="chromadb"
VECDB_PORT="8000"
IMP_DATA_FOLDER="/app/data"
